{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "269ebfd3",
   "metadata": {},
   "source": [
    "\n",
    "## Q1: Simple Linear Regression vs. Multiple Linear Regression\n",
    "\n",
    "### Simple Linear Regression:\n",
    "Simple Linear Regression involves modeling the relationship between two variables - one independent variable (predictor) and one dependent variable (response). It assumes a linear relationship between the variables and aims to find the best-fitting line that minimizes the sum of squared differences between the observed and predicted values.\n",
    "\n",
    "**Example:**\n",
    "Suppose we want to predict a student's final exam score (dependent variable) based on the number of hours they studied (independent variable).\n",
    "\n",
    "### Multiple Linear Regression:\n",
    "Multiple Linear Regression extends the concept of linear regression to multiple independent variables. It models the relationship between one dependent variable and two or more independent variables. It aims to find the best-fitting hyperplane in a higher-dimensional space.\n",
    "\n",
    "**Example:**\n",
    "Predicting a house's price (dependent variable) based on various features like square footage, number of bedrooms, and distance to the city center (independent variables).\n",
    "\n",
    "## Q2: Assumptions of Linear Regression and Checking Assumptions\n",
    "\n",
    "Assumptions of Linear Regression:\n",
    "1. Linearity: The relationship between independent and dependent variables is linear.\n",
    "2. Independence: Residuals (differences between observed and predicted values) are independent of each other.\n",
    "3. Homoscedasticity: Residuals have constant variance across all levels of the predictor variables.\n",
    "4. Normality: Residuals are normally distributed.\n",
    "\n",
    "To check assumptions:\n",
    "- **Residual Plot:** Plot residuals vs. predicted values to check linearity and homoscedasticity.\n",
    "- **Normality Plot:** Plot residuals vs. a normal distribution to check normality.\n",
    "- **Durbin-Watson Test:** Checks for independence of residuals.\n",
    "- **Variance Inflation Factor (VIF):** Checks for multicollinearity (related to Q6).\n",
    "\n",
    "## Q3: Interpretation of Slope and Intercept\n",
    "\n",
    "In a simple linear regression equation (y = mx + b), the slope (m) represents the change in the dependent variable for a unit change in the independent variable. The intercept (b) represents the predicted value of the dependent variable when the independent variable is zero.\n",
    "\n",
    "**Example:**\n",
    "For the student's exam score prediction, the slope represents the increase in the final exam score for each additional hour studied. The intercept represents the expected score when the student hasn't studied at all.\n",
    "\n",
    "## Q4: Gradient Descent in Machine Learning\n",
    "\n",
    "Gradient Descent is an optimization algorithm used to minimize the loss function in machine learning models. It iteratively adjusts the model parameters in the direction of steepest descent (negative gradient) to reach the optimal values. It's widely used in training various machine learning models, including linear regression, neural networks, and more.\n",
    "\n",
    "## Q5: Multiple Linear Regression Model\n",
    "\n",
    "Multiple Linear Regression models the relationship between a dependent variable and multiple independent variables. The model equation is:\n",
    "\n",
    "y = b0 + b1*x1 + b2*x2 + ... + bn*xn + ε\n",
    "\n",
    "Where:\n",
    "- y is the dependent variable.\n",
    "- b0 is the intercept.\n",
    "- b1, b2, ..., bn are the coefficients for the independent variables x1, x2, ..., xn.\n",
    "- ε is the error term.\n",
    "\n",
    "## Q6: Multicollinearity in Multiple Linear Regression\n",
    "\n",
    "Multicollinearity occurs when two or more independent variables in a multiple linear regression are highly correlated, making it difficult to isolate the individual effect of each variable. It can lead to unstable coefficient estimates and reduced interpretability.\n",
    "\n",
    "To detect multicollinearity:\n",
    "- **Correlation Matrix:** Calculate correlation coefficients between independent variables.\n",
    "- **VIF (Variance Inflation Factor):** High VIF values indicate multicollinearity.\n",
    "\n",
    "To address multicollinearity:\n",
    "- Remove one of the correlated variables.\n",
    "- Combine correlated variables into a single variable.\n",
    "- Use regularization techniques like Ridge or Lasso regression.\n",
    "\n",
    "## Q7: Polynomial Regression Model\n",
    "\n",
    "Polynomial Regression is an extension of linear regression where the relationship between the dependent and independent variables is modeled as an nth-degree polynomial. It can capture non-linear relationships in the data.\n",
    "\n",
    "## Q8: Advantages and Disadvantages of Polynomial Regression\n",
    "\n",
    "Advantages:\n",
    "- Can capture complex non-linear relationships.\n",
    "- More flexible than linear regression.\n",
    "\n",
    "Disadvantages:\n",
    "- Prone to overfitting with higher-degree polynomials.\n",
    "- Interpretability may decrease with increased complexity.\n",
    "\n",
    "**When to Use:**\n",
    "Use polynomial regression when you suspect a non-linear relationship between variables and linear regression doesn't fit well. Be cautious of overfitting and consider using techniques to control model complexity.\n",
    "\n",
    "Please note that this is a textual representation of a Jupyter Notebook-style format. You can adapt this content into an actual Jupyter Notebook by adding code cells for visualization or calculations, if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0743922f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
