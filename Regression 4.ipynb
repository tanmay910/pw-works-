{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f7b756",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Q1. What is Lasso Regression, and how does it differ from other regression techniques?**\n",
    "\n",
    "Lasso Regression, short for \"Least Absolute Shrinkage and Selection Operator,\" is a linear regression technique that incorporates L1 regularization into the linear regression model. It adds a penalty term to the linear regression cost function, which is proportional to the absolute values of the coefficients. This penalty encourages the model to reduce the magnitude of less important coefficients, effectively performing feature selection by driving some coefficients to zero. \n",
    "\n",
    "Differences from other regression techniques:\n",
    "- **Ridge Regression**: While both Ridge and Lasso add regularization terms to the cost function, Ridge uses L2 regularization (penalizing squared magnitudes of coefficients) and may not drive coefficients to exactly zero, keeping all features to some extent. Lasso, on the other hand, can drive coefficients to precisely zero, performing feature selection.\n",
    "\n",
    "- **Elastic Net Regression**: This technique combines both L1 and L2 regularization, providing a balance between Lasso and Ridge.\n",
    "\n",
    "**Q2. What is the main advantage of using Lasso Regression in feature selection?**\n",
    "\n",
    "The main advantage of Lasso Regression in feature selection is its ability to automatically identify and select the most important features while setting less important features' coefficients to zero. This helps in reducing the complexity of the model and mitigates the risk of overfitting. Lasso can handle situations with a high number of features and where many of them might be irrelevant or redundant.\n",
    "\n",
    "**Q3. How do you interpret the coefficients of a Lasso Regression model?**\n",
    "\n",
    "In Lasso Regression, the magnitude of the coefficients reflects their importance in the model. A larger absolute coefficient value indicates a stronger impact of the corresponding feature on the target variable. Features with non-zero coefficients are considered important, while features with coefficients set to zero are effectively excluded from the model.\n",
    "\n",
    "**Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?**\n",
    "\n",
    "The main tuning parameter in Lasso Regression is the regularization parameter, often denoted as \"Î»\" (lambda). This parameter controls the strength of the regularization penalty. Higher values of lambda lead to stronger regularization, which results in more coefficients being pushed to zero. Smaller values of lambda reduce the amount of regularization, allowing the model to fit the data more closely. The choice of lambda depends on the trade-off between model complexity and accuracy.\n",
    "\n",
    "**Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?**\n",
    "\n",
    "Lasso Regression is inherently a linear regression technique and is best suited for linear relationships between features and the target. However, it can be used in combination with feature transformations to handle certain non-linear relationships. For instance, you can create polynomial features or use other transformations like logarithmic or exponential functions to capture non-linear patterns. Alternatively, other non-linear regression techniques like decision trees, random forests, or support vector machines might be more suitable for strongly non-linear problems.\n",
    "\n",
    "**Q6. What is the difference between Ridge Regression and Lasso Regression?**\n",
    "\n",
    "The main difference between Ridge Regression and Lasso Regression lies in the type of regularization applied:\n",
    "- Ridge Regression uses L2 regularization, which adds the sum of squared coefficients to the cost function.\n",
    "- Lasso Regression uses L1 regularization, which adds the sum of absolute coefficients to the cost function.\n",
    "\n",
    "The impact of L2 regularization is that all coefficients are shrunk towards zero, but they are rarely driven exactly to zero. L1 regularization, as seen earlier, can drive coefficients to precisely zero, allowing feature selection. Elastic Net Regression combines both L1 and L2 regularization to offer a balanced approach.\n",
    "\n",
    "**Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?**\n",
    "\n",
    "Yes, Lasso Regression can help handle multicollinearity to some extent due to its ability to shrink coefficients. When features are highly correlated (multicollinear), Lasso might select one of the correlated features and drive the coefficients of others to zero. This can help in simplifying the model and making it more interpretable.\n",
    "\n",
    "**Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?**\n",
    "\n",
    "The optimal value of the regularization parameter (lambda) in Lasso Regression is typically chosen through techniques like cross-validation. You would train the Lasso Regression model with different values of lambda and evaluate its performance on a validation set using metrics like Mean Squared Error (MSE) or cross-validated R-squared. The lambda value that gives the best trade-off between model complexity and accuracy on the validation set is considered the optimal value.\n",
    "\n",
    "Different values of lambda will result in different sets of features being selected (some coefficients being zero). Therefore, the choice of lambda also depends on the interpretability of the model and the specific context of the problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c3a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
